# vqgan-clip

## VQGAN+CLIP methods

### [VQGAN+CLIP_(codebook_sampling_method).ipynb](https://github.com/EleutherAI/vqgan-clip/blob/main/VQGAN%2BCLIP_(codebook_sampling_method).ipynb) ([on Colab](https://colab.research.google.com/drive/15UwYDsnNeldJFHJ9NdgYBYeo6xPmSelP))

Generates images from text prompts with VQGAN and CLIP (codebook sampling method).

### [VQGAN+CLIP_(z+quantize_method).ipynb](https://github.com/EleutherAI/vqgan-clip/blob/main/VQGAN%2BCLIP_(z%2Bquantize_method).ipynb) ([on Colab](https://colab.research.google.com/drive/1L8oL-vLJXVcRzCFbPwOoMkPKJ8-aYdPN))

Generates images from text prompts with VQGAN and CLIP (z+quantize method).

### [VQGAN+CLIP_(Mse regulized z+quantize_method)](https://github.com/EleutherAI/vqgan-clip/blob/main/VQGAN%2BCLIP_(Mse%20regulized%20z%2Bquantize_method).ipynb)

Generates images from text prompts with VQGAN and CLIP (z+quantize method) regulized with MSE.

### [Semantic_Style_Transfer_with_CLIP+VQGAN_(Gumbel_VQGAN).ipynb](https://github.com/EleutherAI/vqgan-clip/blob/main/Semantic_Style_Transfer_with_CLIP%2BVQGAN_(Gumbel_VQGAN).ipynb) ([on Colab](https://colab.research.google.com/drive/1kNZYKlGRkkW4SDoawnq1ZoH0jhnX_jlV))

Zero shot semantic style transfer

## Non-VQGAN CLIP methods

### [OpenAI_dVAE+CLIP.ipynb](https://github.com/EleutherAI/vqgan-clip/blob/main/OpenAI_dVAE%2BCLIP.ipynb) ([on Colab](https://colab.research.google.com/drive/10DzGECHlEnL4oeqsN-FWCkIe_sq3wVqt))

Generates images from text prompts with the OpenAI discrete VAE and CLIP.

### [CLIP_Guided_Diffusion.ipynb](https://github.com/EleutherAI/vqgan-clip/blob/main/CLIP_Guided_Diffusion.ipynb) ([on Colab](https://colab.research.google.com/drive/1ED6_MYVXTApBHzQObUPaaMolgf9hZOOF))

Generates images from text prompts with CLIP guided diffusion.

### [CLIP_Guided_Diffusion_HQ.ipynb](https://github.com/EleutherAI/vqgan-clip/blob/main/CLIP_Guided_Diffusion_HQ.ipynb) ([on Colab](https://colab.research.google.com/drive/12a_Wrfi2_gwwAuN3VvMTwVMz9TfqctNj))

Generates images from text prompts with CLIP guided diffusion.

### [CLIP_Guided_Diffusion_HQ_512x512.ipynb](https://github.com/EleutherAI/vqgan-clip/blob/main/CLIP_Guided_Diffusion_HQ_512x512.ipynb) ([on Colab](https://colab.research.google.com/drive/1V66mUeJbXrTuQITvJunvnWVn96FEbSI3))

Generates images from text prompts with CLIP guided diffusion.

### [CLIP_Guided_Diffusion_HQ_512x512_Uncond.ipynb](https://github.com/EleutherAI/vqgan-clip/blob/main/CLIP_Guided_Diffusion_HQ_512x512_Uncond.ipynb) ([on Colab](https://colab.research.google.com/drive/1QBsaDAZv8np29FPbvjffbE1eytoJcsgA))

Generates images from text prompts with CLIP guided diffusion.

### [CLIP_Decision_Transformer.ipynb](https://github.com/EleutherAI/vqgan-clip/blob/main/CLIP_Decision_Transformer.ipynb) ([on Colab](https://colab.research.google.com/drive/1dFV3GCR5kasYiAl8Bl4fBlLOCdCfjufI))

Generates images from text prompts with a CLIP conditioned Decision Transformer.
