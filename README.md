# vqgan-clip

## VQGAN+CLIP methods

### [VQGAN+CLIP_(codebook_sampling_method).ipynb](https://github.com/EleutherAI/vqgan-clip/blob/main/VQGAN%2BCLIP_(codebook_sampling_method).ipynb)

Generates images from text prompts with VQGAN and CLIP (codebook sampling method).

### [VQGAN+CLIP_(z+quantize_method).ipynb](https://github.com/EleutherAI/vqgan-clip/blob/main/VQGAN%2BCLIP_(z%2Bquantize_method).ipynb)

Generates images from text prompts with VQGAN and CLIP (z+quantize method).

### [VQGAN+CLIP_(Mse regulized z+quantize_method)](https://github.com/EleutherAI/vqgan-clip/blob/main/VQGAN%2BCLIP_(Mse%20regulized%20z%2Bquantize_method).ipynb)

Generates images from text prompts with VQGAN and CLIP (z+quantize method) regulized with MSE.

### [Semantic_Style_Transfer_with_CLIP+VQGAN_(Gumbel_VQGAN).ipynb](https://github.com/EleutherAI/vqgan-clip/blob/main/Semantic_Style_Transfer_with_CLIP%2BVQGAN_(Gumbel_VQGAN).ipynb)

Zero shot semantic style transfer

## Non-VQGAN CLIP methods

### [OpenAI_dVAE+CLIP.ipynb](https://github.com/EleutherAI/vqgan-clip/blob/main/OpenAI_dVAE%2BCLIP.ipynb)

Generates images from text prompts with the OpenAI discrete VAE and CLIP.

### [CLIP_Guided_Diffusion.ipynb](https://github.com/EleutherAI/vqgan-clip/blob/main/CLIP_Guided_Diffusion.ipynb)

Generates images from text prompts with CLIP guided diffusion.

### [CLIP_Guided_Diffusion_HQ.ipynb](https://github.com/EleutherAI/vqgan-clip/blob/main/CLIP_Guided_Diffusion_HQ.ipynb)

Generates images from text prompts with CLIP guided diffusion.

### [CLIP_Guided_Diffusion_HQ_512x512.ipynb](https://github.com/EleutherAI/vqgan-clip/blob/main/CLIP_Guided_Diffusion_HQ_512x512.ipynb)

Generates images from text prompts with CLIP guided diffusion.

### [CLIP_Decision_Transformer.ipynb](https://github.com/EleutherAI/vqgan-clip/blob/main/CLIP_Decision_Transformer.ipynb)

Generates images from text prompts with a CLIP conditioned Decision Transformer.
